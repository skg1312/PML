{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1d381c7",
   "metadata": {},
   "source": [
    "# Problem 2: Retail Customer Segmentation and Sales Prediction\n",
    "This notebook is designed to execute each task step-by-step for faster and efficient processing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104ac56e",
   "metadata": {},
   "source": [
    "## 1. Data Preprocessing and Exploratory Analysis\n",
    "### Task: \n",
    "- Check for data quality issues\n",
    "- Analyze correlations between variables\n",
    "- Create meaningful features from the raw data (feature engineering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15e35ea1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>TotalSpent</th>\n",
       "      <th>AvgSpent</th>\n",
       "      <th>PurchaseCount</th>\n",
       "      <th>TotalQuantity</th>\n",
       "      <th>AvgQuantity</th>\n",
       "      <th>UniqueInvoices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12346.0</td>\n",
       "      <td>77183.60</td>\n",
       "      <td>77183.600000</td>\n",
       "      <td>1</td>\n",
       "      <td>74215</td>\n",
       "      <td>74215.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12347.0</td>\n",
       "      <td>4310.00</td>\n",
       "      <td>23.681319</td>\n",
       "      <td>182</td>\n",
       "      <td>2458</td>\n",
       "      <td>13.505495</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12348.0</td>\n",
       "      <td>1797.24</td>\n",
       "      <td>57.975484</td>\n",
       "      <td>31</td>\n",
       "      <td>2341</td>\n",
       "      <td>75.516129</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12349.0</td>\n",
       "      <td>1757.55</td>\n",
       "      <td>24.076027</td>\n",
       "      <td>73</td>\n",
       "      <td>631</td>\n",
       "      <td>8.643836</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12350.0</td>\n",
       "      <td>334.40</td>\n",
       "      <td>19.670588</td>\n",
       "      <td>17</td>\n",
       "      <td>197</td>\n",
       "      <td>11.588235</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CustomerID  TotalSpent      AvgSpent  PurchaseCount  TotalQuantity  \\\n",
       "0     12346.0    77183.60  77183.600000              1          74215   \n",
       "1     12347.0     4310.00     23.681319            182           2458   \n",
       "2     12348.0     1797.24     57.975484             31           2341   \n",
       "3     12349.0     1757.55     24.076027             73            631   \n",
       "4     12350.0      334.40     19.670588             17            197   \n",
       "\n",
       "    AvgQuantity  UniqueInvoices  \n",
       "0  74215.000000               1  \n",
       "1     13.505495               7  \n",
       "2     75.516129               4  \n",
       "3      8.643836               1  \n",
       "4     11.588235               1  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "file_path = './Datasets/Online Retail.xlsx'  # Update with the file path\n",
    "data = pd.read_excel(file_path)\n",
    "\n",
    "# Data cleaning\n",
    "data.dropna  # Drop missing values\n",
    "data = data[data['Quantity'] > 0]  # Remove negative quantities\n",
    "\n",
    "# Feature Engineering\n",
    "data['TotalPrice'] = data['Quantity'] * data['UnitPrice']\n",
    "data['InvoiceDate'] = pd.to_datetime(data['InvoiceDate'])\n",
    "data['Year'] = data['InvoiceDate'].dt.year\n",
    "data['Month'] = data['InvoiceDate'].dt.month\n",
    "customer_features = data.groupby('CustomerID').agg({\n",
    "    'TotalPrice': ['sum', 'mean', 'count'],\n",
    "    'Quantity': ['sum', 'mean'],\n",
    "    'InvoiceNo': 'nunique'\n",
    "}).reset_index()\n",
    "customer_features.columns = ['CustomerID', 'TotalSpent', 'AvgSpent', 'PurchaseCount', \n",
    "                             'TotalQuantity', 'AvgQuantity', 'UniqueInvoices']\n",
    "customer_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e297643",
   "metadata": {},
   "source": [
    "## 2. Customer Segmentation\n",
    "### Task:\n",
    "- Apply both K-means and Hierarchical Clustering\n",
    "- Compare different distance measures (Euclidean, Manhattan, etc.)\n",
    "- Determine the optimal number of clusters using silhouette score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a002ce44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-means Silhouette Score: 0.9467414220172158\n",
      "Hierarchical Silhouette Score: 0.6495786986326426\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Prepare data for clustering\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(customer_features.drop('CustomerID', axis=1))\n",
    "\n",
    "# K-means clustering\n",
    "kmeans = KMeans(n_clusters=5, random_state=42, n_init='auto')\n",
    "kmeans_labels = kmeans.fit_predict(scaled_data)\n",
    "silhouette_kmeans = silhouette_score(scaled_data, kmeans_labels)\n",
    "\n",
    "# Hierarchical clustering\n",
    "hierarchical = AgglomerativeClustering(n_clusters=5)\n",
    "hierarchical_labels = hierarchical.fit_predict(scaled_data)\n",
    "silhouette_hierarchical = silhouette_score(scaled_data, hierarchical_labels)\n",
    "\n",
    "print(f\"K-means Silhouette Score: {silhouette_kmeans}\")\n",
    "print(f\"Hierarchical Silhouette Score: {silhouette_hierarchical}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f19aff",
   "metadata": {},
   "source": [
    "## 3,4 Regression Models for Sales Prediction\n",
    "### Task:\n",
    "- For each customer segment, build regression models to predict future purchase amounts\n",
    "- Regression Models: Decision Trees, Random Forest, Gradient Boosting, XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11e298f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segment 4 has less than 2 samples. Skipping train-test split.\n",
      "Segment 1 has less than 2 samples. Skipping train-test split.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dbda38\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1266: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "C:\\Users\\dbda38\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1266: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "C:\\Users\\dbda38\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1266: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "C:\\Users\\dbda38\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1266: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: {'DecisionTree': {'MAE': 296.21081228273465,\n",
       "   'RMSE': 821.0681150209646,\n",
       "   'R2': 0.8985859747671091},\n",
       "  'RandomForest': {'MAE': 223.6607169640787,\n",
       "   'RMSE': 802.2659066475717,\n",
       "   'R2': 0.9031774938981155},\n",
       "  'GradientBoosting': {'MAE': 235.41151942102516,\n",
       "   'RMSE': 575.2008919582315,\n",
       "   'R2': 0.9502287271179363},\n",
       "  'XGBoost': {'MAE': 209.17373822550098,\n",
       "   'RMSE': 1234.78765302481,\n",
       "   'R2': 0.7706365552447628}},\n",
       " 3: {'DecisionTree': {'MAE': 28599.2525,\n",
       "   'RMSE': 36252.48159033082,\n",
       "   'R2': -0.28921531531335454},\n",
       "  'RandomForest': {'MAE': 36523.08274999997,\n",
       "   'RMSE': 43639.7842748385,\n",
       "   'R2': -0.868164714177758},\n",
       "  'GradientBoosting': {'MAE': 43743.113226262045,\n",
       "   'RMSE': 50678.25682140713,\n",
       "   'R2': -1.5193778736090344},\n",
       "  'XGBoost': {'MAE': 44050.397226562505,\n",
       "   'RMSE': 56218.838972651654,\n",
       "   'R2': -2.1003713817424785}},\n",
       " 2: {'DecisionTree': {'MAE': 7271.8399999999965,\n",
       "   'RMSE': 7271.8399999999965,\n",
       "   'R2': nan},\n",
       "  'RandomForest': {'MAE': 55603.580299999994,\n",
       "   'RMSE': 55603.580299999994,\n",
       "   'R2': nan},\n",
       "  'GradientBoosting': {'MAE': 44295.532851821765,\n",
       "   'RMSE': 44295.532851821765,\n",
       "   'R2': nan},\n",
       "  'XGBoost': {'MAE': 7271.852031249997, 'RMSE': 7271.852031249997, 'R2': nan}}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "import xgboost as xgb\n",
    "import json\n",
    "customer_features['Segment'] = kmeans_labels  # Use the best clustering result\n",
    "models = {'DecisionTree': DecisionTreeRegressor,\n",
    "          'RandomForest': RandomForestRegressor,\n",
    "          'GradientBoosting': GradientBoostingRegressor,\n",
    "          'XGBoost': xgb.XGBRegressor}\n",
    "\n",
    "results = {}\n",
    "for segment in customer_features['Segment'].unique():\n",
    "    segment_data = customer_features[customer_features['Segment'] == segment]\n",
    "    X = segment_data.drop(['CustomerID', 'Segment', 'TotalSpent'], axis=1)\n",
    "    y = segment_data['TotalSpent']\n",
    "    \n",
    "    # Check if the segment has enough samples for splitting\n",
    "    if len(X) < 2:\n",
    "        print(f\"Segment {segment} has less than 2 samples. Skipping train-test split.\")\n",
    "        continue  # Skip this segment\n",
    "    \n",
    "    # Perform train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    segment_results = {}\n",
    "    for model_name, model_class in models.items():\n",
    "        model = model_class()\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        rmse = mean_squared_error(y_test, y_pred)**0.5\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        segment_results[model_name] = {'MAE': mae, 'RMSE': rmse, 'R2': r2}\n",
    "    results[segment] = segment_results\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae73740c",
   "metadata": {},
   "source": [
    "## 5. Apply PCA for Dimensionality Reduction\n",
    "### Task:\n",
    "- Reduce dimensionality and improve model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8a3c6e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Variance Ratio: 0.9775011628108644\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA(n_components=0.95)\n",
    "reduced_data = pca.fit_transform(scaled_data)\n",
    "print(f\"Explained Variance Ratio: {np.sum(pca.explained_variance_ratio_)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641a0907",
   "metadata": {},
   "source": [
    "## 6. Temporal Validation Strategy (Optional)\n",
    "### Task:\n",
    "- Design a model selection and validation strategy that accounts for temporal aspects of customer behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8f32cec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segment 4 has fewer samples (1) than the required number of folds (3). Skipping temporal validation.\n",
      "Segment 2 has fewer samples (3) than the required number of folds (3). Skipping temporal validation.\n",
      "Segment 1 has fewer samples (1) than the required number of folds (3). Skipping temporal validation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: [{'MAE': 258.70257268008936,\n",
       "   'RMSE': 1540.7882052314956,\n",
       "   'R2': 0.7387679837008345},\n",
       "  {'MAE': 353.43290990177417,\n",
       "   'RMSE': 2365.5903895910524,\n",
       "   'R2': 0.33100960949773983},\n",
       "  {'MAE': 204.36657988337728,\n",
       "   'RMSE': 978.95689688164,\n",
       "   'R2': 0.8504514442992057}],\n",
       " 3: [{'MAE': 71382.43894531249,\n",
       "   'RMSE': 116516.33802385171,\n",
       "   'R2': -0.24032438300237136},\n",
       "  {'MAE': 20086.533515625,\n",
       "   'RMSE': 21581.41209811239,\n",
       "   'R2': -0.6331528810584097},\n",
       "  {'MAE': 80677.770703125,\n",
       "   'RMSE': 104309.92692489285,\n",
       "   'R2': -0.6836524394515175}]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import xgboost as xgb\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=3)  # Default number of splits\n",
    "temporal_results = {}\n",
    "\n",
    "for segment in customer_features['Segment'].unique():\n",
    "    segment_data = customer_features[customer_features['Segment'] == segment]\n",
    "    X = segment_data.drop(['CustomerID', 'Segment', 'TotalSpent'], axis=1)\n",
    "    y = segment_data['TotalSpent']\n",
    "    \n",
    "    # Check if the segment has enough samples for TimeSeriesSplit\n",
    "    if len(X) <= tscv.n_splits:\n",
    "        print(f\"Segment {segment} has fewer samples ({len(X)}) than the required number of folds ({tscv.n_splits}). Skipping temporal validation.\")\n",
    "        continue  # Skip this segment\n",
    "    \n",
    "    segment_results = []\n",
    "    for train_index, test_index in tscv.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        # Train the model\n",
    "        model = xgb.XGBRegressor()\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Evaluate the model\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        rmse = mean_squared_error(y_test, y_pred)**0.5\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        segment_results.append({'MAE': mae, 'RMSE': rmse, 'R2': r2})\n",
    "    \n",
    "    temporal_results[segment] = segment_results\n",
    "\n",
    "temporal_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4d7c3c-1d2d-43f7-91e8-2a58f50c155f",
   "metadata": {},
   "source": [
    "# 7. Implement regularization techniques to prevent overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a72adb40-93c5-4464-ba1c-5bf4fe4372f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Ridge (L2)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dbda38\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:317: UserWarning: The total space of parameters 5 is smaller than n_iter=10. Running 5 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Lasso (L1)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dbda38\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:317: UserWarning: The total space of parameters 5 is smaller than n_iter=10. Running 5 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ridge (L2):\n",
      "  Best Params: {'model__alpha': 100}\n",
      "  MAE: 10.6999\n",
      "  RMSE: 52.3101\n",
      "  R²: 0.3539\n",
      "\n",
      "Lasso (L1):\n",
      "  Best Params: {'model__alpha': 1}\n",
      "  MAE: 10.5962\n",
      "  RMSE: 54.0803\n",
      "  R²: 0.3094\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "# Preprocessing numeric and categorical columns\n",
    "numeric_columns = ['Quantity', 'UnitPrice', 'Year', 'Month']\n",
    "categorical_columns = ['CustomerID', 'Country']\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "X = data.drop(['TotalPrice'], axis=1)  # Target variable\n",
    "y = data['TotalPrice']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_columns),  # Scale numeric features\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_columns)  # Encode categorical features\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    \"Ridge (L2)\": Ridge(),\n",
    "    \"Lasso (L1)\": Lasso()\n",
    "}\n",
    "\n",
    "# Hyperparameter grids for RandomizedSearchCV\n",
    "param_grids = {\n",
    "    \"Ridge (L2)\": {'model__alpha': [0.01, 0.1, 1, 10, 100]},\n",
    "    \"Lasso (L1)\": {'model__alpha': [0.01, 0.1, 1, 10, 100]}\n",
    "}\n",
    "\n",
    "# Train and evaluate models\n",
    "results = {}\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Training {model_name}...\")\n",
    "\n",
    "    # Model pipeline\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', model)\n",
    "    ])\n",
    "    \n",
    "    # Hyperparameter tuning with RandomizedSearchCV\n",
    "    random_search = RandomizedSearchCV(\n",
    "        estimator=pipeline,\n",
    "        param_distributions=param_grids[model_name],\n",
    "        n_iter=10,  # Number of random combinations\n",
    "        cv=3,  # 3-fold cross-validation\n",
    "        scoring='neg_mean_squared_error',\n",
    "        random_state=42,\n",
    "        n_jobs=-1  # Parallel processing\n",
    "    )\n",
    "    random_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Best model and evaluation\n",
    "    best_model = random_search.best_estimator_\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = mean_squared_error(y_test, y_pred)**0.5\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    # Store results\n",
    "    results[model_name] = {\n",
    "        \"Best Params\": random_search.best_params_,\n",
    "        \"MAE\": mae,\n",
    "        \"RMSE\": rmse,\n",
    "        \"R²\": r2\n",
    "    }\n",
    "\n",
    "# Display results\n",
    "for model_name, metrics in results.items():\n",
    "    print(f\"\\n{model_name}:\")\n",
    "    print(f\"  Best Params: {metrics['Best Params']}\")\n",
    "    print(f\"  MAE: {metrics['MAE']:.4f}\")\n",
    "    print(f\"  RMSE: {metrics['RMSE']:.4f}\")\n",
    "    print(f\"  R²: {metrics['R²']:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
